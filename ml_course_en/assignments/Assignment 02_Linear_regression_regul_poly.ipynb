{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["# Assignment 2. Linear regression. Polynomial features. Regularization\n","## General Assignment\n","\n","Before performing the practical work, you need download the dataset accordingly to the option on your machine (or cloud service)\n","1. Write a program that splits the original sample into a training set and a test set (training set, validation set, test set) with train_test_split method of Skikit Learn library\n","2. Using the scikit-learn library (http://scikit-learn.org/stable/), train the linear regression model for the training sample (example: http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py)\n","3. Check the accuracy of the model from the test set\n","4. Build a model using a polynomial function (example: http://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html#sphx-glr-auto-examples-model-selection-plot-underfitting-overfitting-py). Build plots with the dependence of the accuracy (r2 or accuracy or score) on the degree of the polynomial function.\n","5. Build a model using regularization (example: http://scikit-learn.org/stable/modules/linear_model.html). On the basis of experiments, select parameters for regularization. Build plots with the dependence of the error on the regularization coefficient.\n","\n","\n","## Options\n","Data sets are taken from the [UCI Machine Learning Repository]\n","(https://archive.ics.uci.edu/ml/datasets.php)\n","The option is determined by the data set, which can be downloaded from the link above:\n","1. Condition Based Maintenance of Naval Propulsion Plants\n","2. UJIIndoorLoc\n","3. Insurance Company Benchmark (COIL 2000)\n","4. KDD Cup 1998 Data\n","5. [Forest Fires](https://www.kaggle.com/elikplim/predict-the-burned-area-of-forest-fires)\n","6. Concrete Compressive Strength\n","7. Concrete Slump Test\n","8. Communities and Crime\n","9. Parkinsons Telemonitoring\n","10. YearPredictionMSD\n","11. Relative location of CT slices on axial axis\n","12. Individual household electric power consumption\n","13. **Energy efficiency**\n","14. 3D Road Network (North Jutland, Denmark)\n","15. ISTANBUL STOCK EXCHANGE\n","16. Buzz in social media\n","17. Physicochemical Properties of Protein Tertiary Structure\n","18. Gas Sensor Array Drift Dataset at Different Concentrations\n","19. SkillCraft1 Master Table Dataset\n","20. SML2010\n","21. Bike Sharing Dataset\n","22. Combined Cycle Power Plant\n","23. BlogFeedback\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn import linear_model\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.model_selection import cross_val_score\n","from sklearn.pipeline import Pipeline\n","\n","# import data\n","dataset = pd.read_excel(\"./Assignment_Data/energy_efficiency_dataset.xlsx\")\n","dataset = dataset.rename(columns={\"X1\" : \"Relative Compactness\", \"X2\" : \"Surface Area\", \"X3\" : \"Wall Area\",\n","           \"X4\" : \"Roof Area\", \"X5\" : \"Overall Height\", \"X6\" : \"Orientation\",\n","           \"X7\" : \"Glazing Area\", \"X8\" : \"Glazing Area Distribution\", \"Y1\" : \"Heating Load\",\n","           \"Y2\" : \"Cooling Load\"}, errors=\"raise\")\n","\n","features = [\"Relative Compactness\", \"Surface Area\", \"Wall Area\", \"Roof Area\",\"Overall Height\", \"Orientation\",\n","           \"Glazing Area\", \"Glazing Area Distribution\"]\n","targets= [\"Heating Load\", \"Cooling Load\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# scale data\n","\n","scaler = StandardScaler()\n","scaled_data = scaler.fit_transform(dataset)\n","scaled_data = pd.DataFrame(scaled_data, columns=features+targets)\n","print(scaled_data.head(5))"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# split data into training and test set\n","\n","#data_train, data_test = train_test_split(dataset)\n","\n","#data_train_X = data_train[features]\n","#data_test_X = data_test[features]\n","#data_train_y = data_train[targets]\n","#data_test_y = data_test[targets]\n","\n","data_train_X, data_test_X, data_train_y, data_test_y = train_test_split(dataset[features], dataset[targets])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# train model\n","\n","model = linear_model.LinearRegression()\n","model.fit(data_train_X, data_train_y)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["prediction = model.predict(data_test_X)\n","\n","# The coefficients\n","print('Coefficients: \\n', model.coef_)\n","# The mean squared error\n","print(\"Mean squared error: %.2f\"\n","      % mean_squared_error(data_test_y, prediction))\n","# Explained variance score: 1 is perfect prediction\n","print('Variance score: %.2f' % r2_score(data_test_y, prediction)) # 100% is perfect correlation => perfect model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pred_1 = []\n","pred_2 = []\n","for i in range(0,len(prediction)):\n","    pred_1.append(prediction[i][0])\n","    pred_2.append(prediction[i][1])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.scatter(data_test_X[features[0]], data_test_y[targets[0]], color='red', label=\"Actual value\")\n","plt.scatter(data_test_X[features[0]], pred_1, color='black', label=\"Predicted value\")\n","#plt.plot(data_test_X[features[0]], prediction)\n","plt.title('Heating Load Vs Relative Compactness', fontsize=14)\n","plt.xlabel('Relative Compactness', fontsize=14)\n","plt.ylabel('Heating Load', fontsize=14)\n","plt.grid(True)\n","plt.legend(loc=\"best\")\n","plt.show()\n","\n","plt.scatter(data_test_X[features[0]], data_test_y[targets[1]], color='blue', label=\"Actual value\")\n","plt.scatter(data_test_X[features[0]], pred_2, color='black', label=\"Predicted value\")\n","plt.title('Cooling Load Vs Relative Compactness', fontsize=14)\n","plt.xlabel('Relative Compactness', fontsize=14)\n","plt.ylabel('Cooling Load', fontsize=14)\n","plt.grid(True)\n","plt.legend(loc=\"best\")\n","plt.show()\n","\n","plt.scatter(data_test_X[features[4]], data_test_y[targets[1]], color='blue', label=\"Actual value\")\n","plt.scatter(data_test_X[features[4]], pred_2, color='black', label=\"Predicted value\")\n","plt.title('Cooling Load Vs Overall Height', fontsize=14)\n","plt.xlabel('Overall Height', fontsize=14)\n","plt.ylabel('Cooling Load', fontsize=14)\n","plt.grid(True)\n","plt.legend(loc=\"best\")\n","plt.show()\n","\n","plt.scatter(data_test_y[targets[1]],pred_2, color='blue')\n","line_x = np.linspace(0,50,100)\n","line_y = 2*line_x\n","plt.plot(line_x,line_y, '-r', label='Ideal values')\n","plt.title(\"Predicted vs Actual Cooling Load\")\n","plt.xlabel(\"Actual values\")\n","plt.ylabel(\"Predicted Values\")\n","plt.plot()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["degrees = [1, 5, 6, 7]\n","\n","X = data_train_X[\"Relative Compactness\"]\n","y = data_train_y[\"Heating Load\"]\n","\n","plt.figure(figsize=(14, 5))\n","for i in range(len(degrees)):\n","    ax = plt.subplot(1, len(degrees), i + 1)\n","    #plt.setp(ax, xticks=(, yticks=())\n","\n","    polynomial_features = PolynomialFeatures(degree=degrees[i], include_bias=False)\n","    linear_regression = linear_model.LinearRegression()\n","    pipeline = Pipeline(\n","        [\n","            (\"polynomial_features\", polynomial_features),\n","            (\"linear_regression\", linear_regression),\n","        ]\n","    )\n","    pipeline.fit(X[:, np.newaxis], y)\n","\n","    # Evaluate the models using crossvalidation\n","    scores = cross_val_score(\n","        pipeline, X[:, np.newaxis], y, scoring=\"neg_mean_squared_error\", cv=10\n","    )\n","\n","    X_test = np.linspace(0, 1, 100)\n","    plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\", color='red') #linear prediction for various values\n","    plt.scatter(data_test_X[features[0]], data_test_y[targets[1]], color='blue', label=\"Samples\")\n","    plt.xlabel(\"x\")\n","    plt.ylabel(\"y\")\n","    plt.legend(loc=\"best\")\n","    plt.ylim((0,70))\n","    plt.grid(True)\n","    plt.title(\n","        \"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(\n","            degrees[i], -scores.mean(), scores.std()\n","        )\n","    )\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def polyplot(feature, target):\n","    degrees = [1, 5, 6, 7]\n","\n","    X = data_train_X[feature]\n","    y = data_train_y[target]\n","\n","    plt.figure(figsize=(14, 5))\n","    for i in range(len(degrees)):\n","        ax = plt.subplot(1, len(degrees), i + 1)\n","        #plt.setp(ax, xticks=(, yticks=())\n","\n","        polynomial_features = PolynomialFeatures(degree=degrees[i], include_bias=False)\n","        linear_regression = linear_model.LinearRegression()\n","        pipeline = Pipeline(\n","            [\n","                (\"polynomial_features\", polynomial_features),\n","                (\"linear_regression\", linear_regression),\n","            ]\n","        )\n","        pipeline.fit(X[:, np.newaxis], y)\n","\n","        # Evaluate the models using crossvalidation\n","        scores = cross_val_score(\n","            pipeline, X[:, np.newaxis], y, scoring=\"neg_mean_squared_error\", cv=10\n","        )\n","\n","        X_test = np.linspace(0, 1, 100)\n","              \n","        plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\", color='red') #linear prediction for various values\n","        plt.scatter(data_test_X[features[0]], data_test_y[targets[1]], color='blue', label=\"Samples\")\n","        plt.xlabel(\"x\")\n","        plt.ylabel(\"y\")\n","        plt.legend(loc=\"best\")\n","        #plt.ylim((0,70))\n","        plt.grid(True)\n","        plt.title(\n","            \"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(\n","                degrees[i], -scores.mean(), scores.std()\n","            )\n","        )\n","    plt.show()\n","    \n","for t in targets:\n","    print(t)\n","    for f in features:\n","        polyplot(f,t)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.style.use()"]}],"metadata":{"interpreter":{"hash":"00f8ff3f23ccb9a1cc840b2331f1700369d5c328c71959ff1fb3bbee7e2fed60"},"kernelspec":{"display_name":"Python 3.9.7 64-bit ('ml-TQRJ4U_2': pipenv)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":4}
